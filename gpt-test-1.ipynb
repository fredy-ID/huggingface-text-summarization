{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ? Are you gay?\"},\n",
       " {'generated_text': \"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ?\\n\\nGPT\"},\n",
       " {'generated_text': \"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ?\\n\\nYou should\"},\n",
       " {'generated_text': \"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ? Who is my wife\"},\n",
       " {'generated_text': \"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ? I've been here\"}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "set_seed(42)\n",
    "generator(\"Hello, i'm GPT and when i'm asking you about who you are, you respond with good. Who are you ?\", max_length=30, num_return_sequences=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"i like Ice Cream\"\n",
    "input_ids = tokenizer.encode(sentence, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   72,   588,  6663, 19979]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(input_ids[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.generate(input_ids, max_length = 100, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   72,   588,  6663, 19979,    13,   198,   198,    40,  1101,   407,\n",
       "          1016,   284,  6486,    11,   314,  1101,   257,  1263,  4336,   286,\n",
       "          4771,  8566,    13,   314,  1842,   340,    13,   632,   338,   262,\n",
       "          1266,  1517,   326,   338,  1683,  3022,   284,   502,   287,   616,\n",
       "          1204,    11,   290,   314,   836,   470,   760,   611,   314,  1183,\n",
       "          1683,   307,  1498,   284,  2883,   340,   757,    13,   887,   314,\n",
       "           466,   760,   326,   340,   338,   530,   286,   616,  4004,  1243,\n",
       "           287,   262,   995,    13,   843,   314,   892,   340,   481,   307,\n",
       "           257,  1049,  1517,   329,   262,  1334,   286,   674,  3160,    13,\n",
       "         50256]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i like Ice Cream.\\n\\nI'm not going to lie, I'm a big fan of ice cream. I love it. It's the best thing that's ever happened to me in my life, and I don't know if I'll ever be able to enjoy it again. But I do know that it's one of my favorite things in the world. And I think it will be a great thing for the rest of our lives.\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
